---

title: Loss


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/01_loss.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/01_loss.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="CombinedLoss" class="doc_header"><code>class</code> <code>CombinedLoss</code><a href="https://github.com/bdsaglam/fastmtl/tree/{branch}/fastmtl/loss.py#L10" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>CombinedLoss</code>(<strong>*<code>loss_funcs</code></strong>, <strong><code>weight</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Applies loss functions to multiple model outputs and sums them. If applicable, it can decode and compute activations for each model output.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Assume that a multi-task learning model produces two outputs:</p>
<ol>
<li>The logits for multi-class single-label classification, for which we want to use cross-entropy loss and softmax activation</li>
<li>A logit for single-class classification, for which we want to use binary cross-entropy and sigmoid activation</li>
</ol>
<p><a href="/fastmtl/loss.html#CombinedLoss"><code>CombinedLoss</code></a> enables using the corresponding loss function and its activation function for each model output.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.vision.all</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">ce</span> <span class="o">=</span> <span class="n">CrossEntropyLossFlat</span><span class="p">()</span>
<span class="n">bce</span> <span class="o">=</span> <span class="n">BCEWithLogitsLossFlat</span><span class="p">()</span>
<span class="n">comb_loss</span> <span class="o">=</span> <span class="n">CombinedLoss</span><span class="p">(</span><span class="n">ce</span><span class="p">,</span> <span class="n">bce</span><span class="p">)</span>

<span class="n">bs</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">target1</span><span class="p">,</span> <span class="n">output1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="p">(</span><span class="n">bs</span><span class="p">,)),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="c1"># 5 classes</span>
<span class="n">target2</span><span class="p">,</span> <span class="n">output2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">bs</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">)</span><span class="o">*</span><span class="mi">10</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">comb_loss</span><span class="p">((</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">),</span> <span class="n">target1</span><span class="p">,</span> <span class="n">target2</span><span class="p">)</span>

<span class="n">loss1</span> <span class="o">=</span> <span class="n">ce</span><span class="p">(</span><span class="n">output1</span><span class="p">,</span> <span class="n">target1</span><span class="p">)</span>
<span class="n">loss2</span> <span class="o">=</span> <span class="n">bce</span><span class="p">(</span><span class="n">output2</span><span class="p">,</span> <span class="n">target2</span><span class="p">)</span>
<span class="n">expected</span> <span class="o">=</span> <span class="n">loss1</span> <span class="o">+</span> <span class="n">loss2</span>
<span class="n">test_close</span><span class="p">(</span><span class="n">expected</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here are raw model outputs (logits):</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">[</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[tensor([[-0.1412,  0.5191, -0.8597,  0.8974,  0.9123],
         [ 0.5627, -0.3377, -0.1815, -0.5530,  0.0656],
         [-2.3806, -0.1824,  0.0982,  0.3367, -0.4743],
         [ 1.8762, -0.6613,  0.9129,  0.4719, -0.8340],
         [ 1.3965,  1.0323,  0.5446,  0.6935,  1.0835],
         [-2.0293,  0.5273, -0.7488, -1.1144, -0.7592],
         [ 0.2765, -1.1856, -0.1731,  0.8288,  0.1402],
         [-1.3383, -1.0835, -0.8836, -0.3483, -0.1096]]),
 tensor([ -8.0780,   3.7517, -10.2364, -11.9647,  -5.8247,  -5.0219,  -0.8134,
         -10.2135])]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When applicable, it can decode the raw model outputs and compute activations. For instance, let's decode logits to class label indices and binary classes.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">comb_loss</span><span class="o">.</span><span class="n">decodes</span><span class="p">([</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[tensor([4, 0, 3, 0, 0, 1, 3, 4]),
 tensor([False,  True, False, False, False, False, False, False])]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Similary, here are the activations for each model output.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">comb_loss</span><span class="o">.</span><span class="n">activation</span><span class="p">([</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[tensor([[0.1097, 0.2123, 0.0535, 0.3099, 0.3146],
         [0.3549, 0.1442, 0.1686, 0.1163, 0.2159],
         [0.0228, 0.2057, 0.2723, 0.3456, 0.1536],
         [0.5641, 0.0446, 0.2153, 0.1385, 0.0375],
         [0.2987, 0.2075, 0.1274, 0.1479, 0.2184],
         [0.0425, 0.5475, 0.1528, 0.1060, 0.1512],
         [0.2232, 0.0517, 0.1424, 0.3878, 0.1948],
         [0.1003, 0.1294, 0.1580, 0.2698, 0.3426]]),
 tensor([3.1019e-04, 9.7706e-01, 3.5840e-05, 6.3648e-06, 2.9451e-03, 6.5491e-03,
         3.0717e-01, 3.6672e-05])]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

