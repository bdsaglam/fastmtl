---

title: Loss


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/01_loss.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/01_loss.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="CombinedLoss" class="doc_header"><code>class</code> <code>CombinedLoss</code><a href="https://github.com/bdsaglam/fastmtl/tree/{branch}/fastmtl/loss.py#L10" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>CombinedLoss</code>(<strong>*<code>loss_funcs</code></strong>, <strong><code>weight</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Applies loss functions to multiple model outputs and sums them.
If applicable, it can decode and compute activations for each model output.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Assume that a multi-task learning model produces two outputs:</p>
<ol>
<li>The logits for multi-class single-label classification, for which we want to use cross-entropy loss and softmax activation</li>
<li>A logit for single-class classification, for which we want to use binary cross-entropy and sigmoid activation</li>
</ol>
<p><a href="/fastmtl/loss.html#CombinedLoss"><code>CombinedLoss</code></a> enables using the corresponding loss function and its activation function for each model output.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.vision.all</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">ce</span> <span class="o">=</span> <span class="n">CrossEntropyLossFlat</span><span class="p">()</span>
<span class="n">bce</span> <span class="o">=</span> <span class="n">BCEWithLogitsLossFlat</span><span class="p">()</span>
<span class="n">comb_loss</span> <span class="o">=</span> <span class="n">CombinedLoss</span><span class="p">(</span><span class="n">ce</span><span class="p">,</span> <span class="n">bce</span><span class="p">)</span>

<span class="n">bs</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">target1</span><span class="p">,</span> <span class="n">output1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="p">(</span><span class="n">bs</span><span class="p">,)),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="c1"># 5 classes</span>
<span class="n">target2</span><span class="p">,</span> <span class="n">output2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">bs</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">)</span><span class="o">*</span><span class="mi">10</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">comb_loss</span><span class="p">((</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">),</span> <span class="n">target1</span><span class="p">,</span> <span class="n">target2</span><span class="p">)</span>

<span class="n">loss1</span> <span class="o">=</span> <span class="n">ce</span><span class="p">(</span><span class="n">output1</span><span class="p">,</span> <span class="n">target1</span><span class="p">)</span>
<span class="n">loss2</span> <span class="o">=</span> <span class="n">bce</span><span class="p">(</span><span class="n">output2</span><span class="p">,</span> <span class="n">target2</span><span class="p">)</span>
<span class="n">expected</span> <span class="o">=</span> <span class="n">loss1</span> <span class="o">+</span> <span class="n">loss2</span>
<span class="n">test_close</span><span class="p">(</span><span class="n">expected</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span>

<span class="c1"># activations</span>
<span class="n">actual_acts_output1</span><span class="p">,</span> <span class="n">actual_acts_output2</span> <span class="o">=</span> <span class="n">comb_loss</span><span class="o">.</span><span class="n">activation</span><span class="p">([</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">])</span>
<span class="n">expected_acts_output1</span><span class="p">,</span> <span class="n">expected_acts_output2</span> <span class="o">=</span> <span class="n">ce</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">output1</span><span class="p">),</span> <span class="n">bce</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">output2</span><span class="p">)</span>
<span class="n">test_close</span><span class="p">(</span><span class="n">expected_acts_output1</span><span class="p">,</span> <span class="n">actual_acts_output1</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">expected_acts_output2</span><span class="p">,</span> <span class="n">actual_acts_output2</span><span class="p">)</span>

<span class="c1"># decoding</span>
<span class="n">actual_decoded_output1</span><span class="p">,</span> <span class="n">actual_decoded_output2</span> <span class="o">=</span> <span class="n">comb_loss</span><span class="o">.</span><span class="n">decodes</span><span class="p">([</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">])</span>
<span class="n">expected_decoded_output1</span><span class="p">,</span> <span class="n">expected_decoded_output2</span> <span class="o">=</span> <span class="n">ce</span><span class="o">.</span><span class="n">decodes</span><span class="p">(</span><span class="n">output1</span><span class="p">),</span> <span class="n">bce</span><span class="o">.</span><span class="n">decodes</span><span class="p">(</span><span class="n">output2</span><span class="p">)</span>
<span class="n">test_close</span><span class="p">(</span><span class="n">expected_decoded_output1</span><span class="p">,</span> <span class="n">actual_decoded_output1</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">expected_decoded_output2</span><span class="p">,</span> <span class="n">actual_decoded_output2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here are raw model outputs (logits):</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">[</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[tensor([[-0.0704,  0.3978, -0.0734, -0.0817,  0.5799],
         [ 0.5904, -0.2582,  0.2694, -0.2678, -0.0801],
         [-0.1434, -0.7269, -0.7748,  1.5109,  0.2760],
         [-1.3234,  0.1135,  1.8447,  1.3900,  1.1048],
         [-0.4743,  0.3586,  0.6237,  0.0995, -1.7103],
         [-1.0282, -0.1217,  1.4803, -2.6635,  0.1207],
         [-1.0878, -0.1865, -0.5548, -1.6343,  0.2949],
         [ 0.8009,  1.0363,  0.1929,  0.3628, -0.1960]]),
 tensor([ -1.9926, -11.5465, -14.1181,  10.7254,  -3.6243,   8.0234,  -6.7252,
          28.0304])]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When applicable, it can decode the raw model outputs and compute activations. For instance, let's decode logits to class label indices and binary classes.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">comb_loss</span><span class="o">.</span><span class="n">decodes</span><span class="p">([</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[tensor([4, 0, 3, 2, 2, 2, 4, 1]),
 tensor([False, False, False,  True, False,  True, False,  True])]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Similary, here are the activations for each model output.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">comb_loss</span><span class="o">.</span><span class="n">activation</span><span class="p">([</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[tensor([[0.1539, 0.2458, 0.1534, 0.1521, 0.2948],
         [0.3238, 0.1386, 0.2348, 0.1372, 0.1656],
         [0.1131, 0.0631, 0.0602, 0.5915, 0.1721],
         [0.0181, 0.0760, 0.4290, 0.2723, 0.2047],
         [0.1196, 0.2750, 0.3585, 0.2122, 0.0347],
         [0.0523, 0.1295, 0.6429, 0.0102, 0.1651],
         [0.1028, 0.2531, 0.1751, 0.0595, 0.4096],
         [0.2615, 0.3309, 0.1424, 0.1687, 0.0965]]),
 tensor([1.1998e-01, 9.6696e-06, 7.3891e-07, 9.9998e-01, 2.5975e-02, 9.9967e-01,
         1.1989e-03, 1.0000e+00])]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

