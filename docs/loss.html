---

title: Loss


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/01_loss.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/01_loss.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="CombinedLoss" class="doc_header"><code>class</code> <code>CombinedLoss</code><a href="https://github.com/bdsaglam/fastmtl/tree/{branch}/fastmtl/loss.py#L10" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>CombinedLoss</code>(<strong>*<code>loss_funcs</code></strong>, <strong><code>weight</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Applies loss functions to multiple model outputs and sums them.
If applicable, it can decode and compute activations for each model output.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Assume that a multi-task learning model produces two outputs:</p>
<ol>
<li>The logits for multi-class single-label classification, for which we want to use cross-entropy loss and softmax activation</li>
<li>A logit for single-class classification, for which we want to use binary cross-entropy and sigmoid activation</li>
</ol>
<p><a href="/fastmtl/loss.html#CombinedLoss"><code>CombinedLoss</code></a> enables using the corresponding loss function and its activation function for each model output.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.vision.all</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">ce</span> <span class="o">=</span> <span class="n">CrossEntropyLossFlat</span><span class="p">()</span>
<span class="n">bce</span> <span class="o">=</span> <span class="n">BCEWithLogitsLossFlat</span><span class="p">()</span>
<span class="n">comb_loss</span> <span class="o">=</span> <span class="n">CombinedLoss</span><span class="p">(</span><span class="n">ce</span><span class="p">,</span> <span class="n">bce</span><span class="p">)</span>

<span class="n">bs</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">target1</span><span class="p">,</span> <span class="n">output1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="p">(</span><span class="n">bs</span><span class="p">,)),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="c1"># 5 classes</span>
<span class="n">target2</span><span class="p">,</span> <span class="n">output2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">bs</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">)</span><span class="o">*</span><span class="mi">10</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">comb_loss</span><span class="p">((</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">),</span> <span class="n">target1</span><span class="p">,</span> <span class="n">target2</span><span class="p">)</span>

<span class="n">loss1</span> <span class="o">=</span> <span class="n">ce</span><span class="p">(</span><span class="n">output1</span><span class="p">,</span> <span class="n">target1</span><span class="p">)</span>
<span class="n">loss2</span> <span class="o">=</span> <span class="n">bce</span><span class="p">(</span><span class="n">output2</span><span class="p">,</span> <span class="n">target2</span><span class="p">)</span>
<span class="n">expected</span> <span class="o">=</span> <span class="n">loss1</span> <span class="o">+</span> <span class="n">loss2</span>
<span class="n">test_close</span><span class="p">(</span><span class="n">expected</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span>

<span class="c1"># activations</span>
<span class="n">actual_acts_output1</span><span class="p">,</span> <span class="n">actual_acts_output2</span> <span class="o">=</span> <span class="n">comb_loss</span><span class="o">.</span><span class="n">activation</span><span class="p">([</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">])</span>
<span class="n">expected_acts_output1</span><span class="p">,</span> <span class="n">expected_acts_output2</span> <span class="o">=</span> <span class="n">ce</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">output1</span><span class="p">),</span> <span class="n">bce</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">output2</span><span class="p">)</span>
<span class="n">test_close</span><span class="p">(</span><span class="n">expected_acts_output1</span><span class="p">,</span> <span class="n">actual_acts_output1</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">expected_acts_output2</span><span class="p">,</span> <span class="n">actual_acts_output2</span><span class="p">)</span>

<span class="c1"># decoding</span>
<span class="n">actual_decoded_output1</span><span class="p">,</span> <span class="n">actual_decoded_output2</span> <span class="o">=</span> <span class="n">comb_loss</span><span class="o">.</span><span class="n">decodes</span><span class="p">([</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">])</span>
<span class="n">expected_decoded_output1</span><span class="p">,</span> <span class="n">expected_decoded_output2</span> <span class="o">=</span> <span class="n">ce</span><span class="o">.</span><span class="n">decodes</span><span class="p">(</span><span class="n">output1</span><span class="p">),</span> <span class="n">bce</span><span class="o">.</span><span class="n">decodes</span><span class="p">(</span><span class="n">output2</span><span class="p">)</span>
<span class="n">test_close</span><span class="p">(</span><span class="n">expected_decoded_output1</span><span class="p">,</span> <span class="n">actual_decoded_output1</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">expected_decoded_output2</span><span class="p">,</span> <span class="n">actual_decoded_output2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here are raw model outputs (logits):</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">[</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[tensor([[-1.1966, -0.9368, -1.4137, -0.2984,  0.4431],
         [ 0.0891, -1.4017, -0.6367,  0.2432, -0.5874],
         [ 0.3650, -0.3818,  0.9312, -1.9950,  0.2156],
         [ 0.3676, -1.1119, -1.0802, -1.3735, -0.4440],
         [ 0.9762, -0.8892,  1.0861, -0.4404, -0.2750],
         [-0.3843, -0.0126,  0.7231,  1.7333,  0.3376],
         [ 0.7361,  0.9656, -1.4666, -2.3691, -0.9199],
         [-0.0581, -0.6878, -1.9764, -0.9484, -0.6963]]),
 tensor([  1.9764,  21.9196, -11.3594,  11.4162,  -9.3616,   1.2402,   7.7606,
         -14.2065])]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When applicable, it can decode the raw model outputs and compute activations. For instance, let's decode logits to class label indices and binary classes.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">comb_loss</span><span class="o">.</span><span class="n">decodes</span><span class="p">([</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[tensor([4, 3, 2, 0, 2, 3, 1, 0]),
 tensor([ True,  True, False,  True, False,  True,  True, False])]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Similary, here are the activations for each model output.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">comb_loss</span><span class="o">.</span><span class="n">activation</span><span class="p">([</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[tensor([[0.0934, 0.1211, 0.0752, 0.2292, 0.4812],
         [0.2955, 0.0665, 0.1430, 0.3447, 0.1502],
         [0.2386, 0.1131, 0.4203, 0.0225, 0.2055],
         [0.4802, 0.1094, 0.1129, 0.0842, 0.2133],
         [0.3572, 0.0553, 0.3987, 0.0866, 0.1022],
         [0.0631, 0.0915, 0.1910, 0.5245, 0.1299],
         [0.3840, 0.4830, 0.0424, 0.0172, 0.0733],
         [0.3819, 0.2035, 0.0561, 0.1568, 0.2017]]),
 tensor([8.7830e-01, 1.0000e+00, 1.1660e-05, 9.9999e-01, 8.5953e-05, 7.7560e-01,
         9.9957e-01, 6.7640e-07])]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

